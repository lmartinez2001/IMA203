{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_8tPk8fYgZa"
      },
      "source": [
        "# Practical work on graph-cut optimization (part 2, multilevel)\n",
        "\n",
        "The objective of this PW is the implementation of the $\\alpha$-expansion and $\\alpha$-$\\beta$ swap approaches for grayscale image denoising. \n",
        "\n",
        "The PyMaxFlow library is used to compute the graph-cut. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y-4ipq0XGDm"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "#%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "\n",
        "import platform\n",
        "import tempfile\n",
        "import os\n",
        "from scipy import ndimage as ndi\n",
        "try:\n",
        "    import maxflow\n",
        "except:\n",
        "    !pip install PyMaxflow #For Google Colab\n",
        "    import maxflow\n",
        "    \n",
        "from bokeh.plotting import figure, output_file, show\n",
        "from bokeh.plotting import show as showbokeh\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "def affiche_pour_colab(im,MINI=None, MAXI=None,titre=''): #special colab, don't look\n",
        "  def normalise_image_pour_bokeh(X,MINI,MAXI):\n",
        "    if MAXI==None:\n",
        "      MAXI = np.max(X)\n",
        "    if MINI==None:\n",
        "      MINI = np.min(X)\n",
        "    imt=np.copy(X.copy())\n",
        "    imt=(np.clip(imt,MINI,MAXI)/(MAXI-MINI))\n",
        "    imt[imt<0]=0\n",
        "    imt[imt>1]=1\n",
        "    imt*=255\n",
        "    sortie=np.empty((*imt.shape,4),dtype=np.uint8)\n",
        "    for k in range(3):\n",
        "      sortie[:,:,k]=imt\n",
        "    sortie[:,:,3]=255\n",
        "    return sortie\n",
        "\n",
        "  img = im\n",
        "  img=normalise_image_pour_bokeh(np.flipud(im),MINI,MAXI)\n",
        "  p = figure(tooltips=[(\"x\", \"$x\"), (\"y\", \"$y\"), (\"value\", \"@image\")], y_range=[im.shape[0], 0], x_range=[0, im.shape[1]], title=titre)\n",
        "  # p.x_range.range_padding = p.y_range.range_padding = 0\n",
        "  # must give a vector of images\n",
        "  p.image(image=[np.flipud(im)], x=0, y=im.shape[0], dw=im.shape[1], dh=im.shape[0], palette=\"Greys9\", level=\"image\")\n",
        "  p.xgrid.visible = False\n",
        "  p.ygrid.visible = False\n",
        "  showbokeh(p)\n",
        "\n",
        "def affiche(im,MINI=0.0, MAXI=None,titre='',printname=False):\n",
        "  affiche_pour_colab(im,MINI=MINI, MAXI=MAXI,titre=titre) # under google colab many options disappear\n",
        "\n",
        "def display_segmentation_borders(image, bin):\n",
        "    imagergb = np.copy(image)\n",
        "    from skimage.morphology import binary_dilation, disk\n",
        "    contour = binary_dilation(bin,disk(15))^bin\n",
        "    imagergb[contour==1,0] = 255\n",
        "    imagergb[contour==1,1] = 0\n",
        "    imagergb[contour==1,2] = 0\n",
        "    return imagergb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuvZnA9KXGER"
      },
      "source": [
        "## 2 Denoising a grayscale image\n",
        "\n",
        "\n",
        "In this second part of the PW, we are interested in using Markovian methods to **denoise** images with different regularization potentials. \n",
        "\n",
        "We are interested in denoising the images *Ibruitee.png* and *Ibruitee2.png* which correspond to the same scene perturbed by two noises of different nature.\n",
        "\n",
        "\n",
        "We will complete programs that call the algorithm of alpha-expansions or Boykov's alpha-beta swap according to the Kolmogorov technique.\n",
        "\n",
        "\n",
        "Q1: What are the respective expressions for the data attachment potentials in the case of noise following a Gaussian distribution (equation 1) and a Rayleigh distribution (equation 2)?\n",
        "\n",
        "\\begin{equation} \n",
        "p(y_p|x_p)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{(y_p-x_p)^2}{2\\sigma^2}\\right],\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation} \n",
        "p(y_p|x_p)=2\\frac{y_p}{x_p^2}\\exp\\left[-\\frac{y_p^2}{x_p^2}\\right].\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RufJ1sxBXGET"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A1: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIXK16BxXGEU"
      },
      "source": [
        "Q2: By studying the histogram of a homogeneous area, indicate which type of noise is present in which image.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mLHdc7RXGEU"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdgSPkwMbipt"
      },
      "source": [
        "im_obs=io.imread('https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/Ibruitee.png') # Observed image, noisy\n",
        "im_obs2=io.imread('https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/Ibruitee2.png') # Observed image, noisy\n",
        "im_orig=io.imread('https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/IoriginaleBW.png') # Reference binary image, to evaluate the quality of the segmentation\n",
        "\n",
        "I = im_obs\n",
        "affiche(im_obs,MINI=0.0, MAXI=255.,titre=\"Noisy image\",printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py2uiyrVXGEV"
      },
      "source": [
        "# select a homogeneous area to study the histogram\n",
        "# we can use the area from 45 to 120 and from 175 to 245\n",
        "affiche(im_obs[:,:],MINI=0.0, MAXI=255.,titre=\"Noisy image\",printname=True)\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(im_obs[:,:].flatten(),50)\n",
        "plt.title('Dark area image 1')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(im_obs2[:,:].flatten(),50)\n",
        "plt.title('Dark area image 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_URNoqaXGEX"
      },
      "source": [
        "\n",
        "We will compare three *a priori* models: the Potts model $\\delta_{x_p=x_q}$, the (discrete) total variation $|x_p-x_q|$, and the (quadratic) Gaussian model $(x_p-x_q)^2$.\n",
        "\n",
        "Q3: Are they metrics or semi-metrics? What can we deduce about the optimization method to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF1p0Iz7XGEX"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A3: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkpjifIHXGEY"
      },
      "source": [
        "Q4: What are the differences between the alpha expansion method and the alpha-beta swap method?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FhVeTAWXGEY"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A4: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEvPlwtMMewg"
      },
      "source": [
        "In the following sections we will use the functions aexpansion_grid and abswap_grid which perform the alpha-expansion and alpha-beta swap respectively. These functions take as input two arguments for a number of levels L :\n",
        "- a tensor of the image size containing in the 3rd dimension the data attachment of each pixel for each considered level (unary term)\n",
        "- a matrix containing the values of the interaction terms between two levels $l_1$ and $l_2$ (depends on the chosen interaction potential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0HKVijFXGEZ"
      },
      "source": [
        "### 2.1 Denoising in the Gaussian case (synthetic image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZj8fxA4XGEZ"
      },
      "source": [
        "from maxflow.fastmin import aexpansion_grid, abswap_grid\n",
        "\n",
        "# Loading images\n",
        "\n",
        "im_obs=io.imread('https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/Ibruitee.png') # Observed image, noisy\n",
        "im_obs2=io.imread('https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/Ibruitee2.png') # Observed image, noisy\n",
        "im_orig=io.imread('https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/IoriginaleBW.png') # Reference binary image, to evaluate the quality of the segmentation\n",
        "\n",
        "I = \n",
        "\n",
        "I = (I/I.max())*255\n",
        "L = 30\n",
        "# Generates L gray levels for nearsest prototype labeling\n",
        "levs = np.arange(0, 255, 255/L)\n",
        "# Calculate data cost as the absolute difference between the label prototype and the pixel value\n",
        "D = np.double(np.abs((I.reshape(I.shape+(1,)) - levs.reshape((1,1,-1)))**2))   \n",
        "\n",
        "affiche(I,MINI=0.0, MAXI=255.,titre=\"Noisy image\",printname=True)\n",
        "\n",
        "# Generate nearest prototype labeling\n",
        "Id = np.argmin(D,2)\n",
        "affiche(Id*255/L,MINI=0.0, MAXI=255.,titre=\"Maximum likelihood denoising\",printname=True)\n",
        "print(D.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JLXkTAiXGEa"
      },
      "source": [
        "Q5: Here, what does the array D correspond to? Explain its dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_JfRGJiXGEb"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A5: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NKHbfwgXGEd"
      },
      "source": [
        "Complete the programs below, and test each regularization model by determining an appropriate beta value each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWez9gd2XGEf"
      },
      "source": [
        "# Potts model regularization\n",
        "# beta values of several hundred\n",
        "beta_Potts = \n",
        "# definition of the regularization matrix V(i,j) for the Potts model\n",
        "V_Potts = np.double(beta_Potts*(np.abs( levs.reshape((-1,1)) - levs.reshape((1,-1)))>0))\n",
        "affiche(V_Potts)\n",
        "\n",
        "# Performs the alpha-expansion based on the data attachment D and the regularization V\n",
        "labels_Potts = aexpansion_grid(D,V_Potts)  \n",
        "affiche(labels_Potts*255/L,MINI=0.0, MAXI=255.0,titre=\"Graph Cut Denoising, Potts regularization, beta = \" + str(beta_Potts),printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRl4Tu3CXGEg"
      },
      "source": [
        "# TV model regularization\n",
        "# beta value of the order of tens\n",
        "beta_TV = \n",
        "# definition of the regularization matrix V(i,j) for the TV model\n",
        "V_TV = \n",
        "affiche(V_TV)\n",
        "\n",
        "# Performs the alpha-expansion based on the data attachment D and the regularization V\n",
        "labels_TV = \n",
        "print(\"Calcul TV terminé\")\n",
        "affiche(labels_TV*255/L,MINI=0.0, MAXI=255.0,titre=\"Graph Cut Denoising, TV regularization, beta = \" + str(beta_TV),printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScWpsJscXGEg"
      },
      "source": [
        "# Quadratic model regularization\n",
        "# beta value of the order of tens\n",
        "beta_quadratic = \n",
        "# definition of the regularization matrix V(i,j) for the quadratic model\n",
        "V_quadratic = \n",
        "affiche(V_quadratic)\n",
        "\n",
        "# Performs the alpha-beta swap based on the data attachment D and the regularization V\n",
        "labels_Quadratic = \n",
        "affiche(labels_Quadratic*255/L,MINI=0.0, MAXI=255,titre=\"Graph Cut Denoising, TV regularization, beta = \" + str(beta_quadratic),printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOIjm_GvXGEj"
      },
      "source": [
        "Q6: Which regularization model do you think is best? Give the best regularization parameter visually found and comment on the results you get in each of the three cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mXb0h35XGEj"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A6: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E03KjnuhXGEk"
      },
      "source": [
        "### 2.2 Denoising in the case of speckle noise (synthetic image)\n",
        "\n",
        "Modify the following cells to fit the model for denoising the im_obs2 image.\n",
        "\n",
        "Q7: Which modifications are needed? (There are several!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vig5FFxSXGEk"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A7: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykgbMadRXGEl"
      },
      "source": [
        "from maxflow.fastmin import aexpansion_grid\n",
        "from numpy import log\n",
        "\n",
        "# Loading image\n",
        "im_obs2=io.imread('https://perso.telecom-paristech.fr/tupin/TPGRAPHCUT/OLD/Ibruitee2.png') # Observed image, noisy\n",
        "I = im_obs2\n",
        "I = (I/I.max())*255\n",
        "affiche(I,MINI=0.0, MAXI=255.,titre=\"Noisy image 2\",printname=True)\n",
        "\n",
        "L = 30\n",
        "# Generates L gray levels for nearsest prototype labeling\n",
        "levs = np.arange(1/L, 255, 255/L)\n",
        "\n",
        "# Calculate data cost as the absolute difference between the label prototype and the pixel value\n",
        "D = -log(2*I.reshape(I.shape+(1,))/levs.reshape((1,1,-1))**2)+(I.reshape(I.shape+(1,))**2/levs.reshape((1,1,-1))**2)\n",
        "print()\n",
        "Id = np.argmin(D,2)\n",
        "\n",
        "# Generate nearest prototype labeling\n",
        "Id = np.argmin(D,2)\n",
        "affiche(Id/L*255,MINI=0.0, MAXI=255.,titre=\"Maximum likelihood denoising\",printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_sNG98TXGEm"
      },
      "source": [
        "# beta value in the order of tenths of a unit\n",
        "beta_Potts = \n",
        "# definition of the Potts potential matrix\n",
        "V_Potts = \n",
        "\n",
        "# Performs the alpha-expansion based on the data attachment D and the regularization V\n",
        "labels_Potts = \n",
        "affiche(labels_Potts*255/L,MINI=0.0, MAXI=255,titre=\"Graph Cut Denoising, Potts regularization, beta = \" + str(beta_Potts),printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D46cNQWXGEn"
      },
      "source": [
        "# beta value in hundredths of a unit\n",
        "beta_TV = \n",
        "# definition of the regularization matrix for TV \n",
        "V_TV = \n",
        "\n",
        "# Performs the alpha-expansion based on the data attachment D and the regularization V\n",
        "labels_TV =  \n",
        "print(\"TV computation completed\")\n",
        "affiche(labels_TV*255/L,MINI=0.0, MAXI=255,titre=\"Graph Cut Denoising, TV regularization, beta = \" + str(beta_TV),printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHoMB9AIXGEn"
      },
      "source": [
        "# beta value in the order of thousandths of a unit\n",
        "beta_quadratic = \n",
        "# definition of the regularization matrix for a quadratic potential\n",
        "V_quadratic =\n",
        "\n",
        "# Performs the alpha-beta swap based on the data attachment D and the regularization V\n",
        "labels_Quadratic = \n",
        "affiche(labels_Quadratic*255/L,MINI=0.0, MAXI=255.,titre=\"Graph Cut Denoising, Quadratic regularization, beta = \" + str(beta_quadratic),printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNwTqDmmXGEo"
      },
      "source": [
        "### 2.3 Denoising a natural image\n",
        "\n",
        "Apply one of the methods used above to denoise the noisy cameraman image. Justify your choice.\n",
        "\n",
        "Q8: Comment on the result obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BYnMvduXGEo"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A8: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAAdzQksXGEq"
      },
      "source": [
        "from skimage.color import rgb2gray\n",
        "import imageio\n",
        "\n",
        "I_cameraman = imageio.imread('http://people.math.sc.edu/Burkardt/data/tif/cameraman.tif')\n",
        "I_cameraman_bruit = I_cameraman + np.random.normal(0,80,I_cameraman.shape)\n",
        "I_cameraman_bruit[I_cameraman_bruit<0] = 0\n",
        "I_cameraman_bruit[I_cameraman_bruit>255] = 255\n",
        "print(I_cameraman.max())\n",
        "\n",
        "affiche(I_cameraman,MINI=0.0, MAXI=255.,titre=\"Image without noise\",printname=True)\n",
        "affiche(I_cameraman_bruit,MINI=0.0, MAXI=255.,titre=\"Noisy image\",printname=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lThTq8-vXGEq"
      },
      "source": [
        "I = (I_cameraman_bruit/I.max())*255\n",
        "L = 250\n",
        "# Generates L gray levels for nearsest prototype labeling\n",
        "levs = \n",
        "# Calculate data cost as the absolute difference between the label prototype and the pixel value\n",
        "D = \n",
        "\n",
        "# choose a regularization model and compute V matrix\n",
        "\n",
        "# compute the appropriate optimization\n",
        "\n",
        "# display the regularized image "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAFknqfAXGEu"
      },
      "source": [
        "### 2.3 SAR Image Denoising\n",
        "\n",
        "SAR (Synthetic Aperture Radar) imagery is a radar-based remote sensing modality that provides images of the Earth in all light and weather conditions. A major drawback is the high speckle noise that affects them. The following cell loads an amplitude image acquired by the Sentinel 1-A satellite over the city of Des Moines in the USA. To limit the computation time, we will work on a small rectangle from the image provided.\n",
        "\n",
        "Adapt one of the methods used previously to denoise the image provided. We will assume that the noise follows a Rayleigh distribution.\n",
        "\n",
        "Q9: Comment on the result obtained.\n",
        "\n",
        "We can compare the result with a denoising obtained by a more recent method (SAR2SAR), based on a Deep Learning approach (the code to display it is provided below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__5ab5afUQGv"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A9: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK1DPdHkXGEw"
      },
      "source": [
        "try:\n",
        "    I_SAR = np.load('noisy_DesMoines_dual_1_corrige_1_VV_AMPLITUDE.npy?dl=1')\n",
        "except:\n",
        "    !wget 'https://www.dropbox.com/s/7m2dw3irho8dpzj/noisy_DesMoines_dual_1_corrige_1_VV_AMPLITUDE.npy?dl=1'\n",
        "    I_SAR = np.load('noisy_DesMoines_dual_1_corrige_1_VV_AMPLITUDE.npy?dl=1')\n",
        "\n",
        "plt.imshow(I_SAR,vmax = 100, cmap = 'gray') # The display is done by truncating the dynamic\n",
        "I_SAR = I_SAR[0:300,0:300]\n",
        "plt.figure()\n",
        "plt.imshow(I_SAR,vmax = 100, cmap = 'gray') # The display is done by truncating the dynamic\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(I_SAR[100:200,100:200].flatten(),200) # Display of the histogram on an almost homogeneous area\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "kaj9Y2rFXGEx"
      },
      "source": [
        "I = (I_SAR/I_SAR.max())*255\n",
        "L = 255\n",
        "# Generates L gray levels for nearsest prototype labeling\n",
        "levs = \n",
        "# Calculate data cost as the neg-log likelihood\n",
        "D = \n",
        "print()\n",
        "affiche(I,MINI=0.0, MAXI=100,titre=\"Noisy image\",printname=True)\n",
        "\n",
        "# choose a regularization model and compute V matrix\n",
        "\n",
        "# compute the appropriate optimization\n",
        "\n",
        "# display the regularized image \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJD1bXP-CXPy"
      },
      "source": [
        "# Display of the denoised image by the SAR2SAR method\n",
        "try:\n",
        "    I_SAR = np.load('denoised_DesMoines_dual_1_corrige_1_VV_AMPLITUDE.npy?dl=1')\n",
        "except:\n",
        "    !wget 'https://www.dropbox.com/s/0f6l0qr6teck5bd/denoised_DesMoines_dual_1_corrige_1_VV_AMPLITUDE.npy?dl=1'\n",
        "    I_SAR = np.load('denoised_DesMoines_dual_1_corrige_1_VV_AMPLITUDE.npy?dl=1')\n",
        "\n",
        "plt.imshow(I_SAR,vmax = 100, cmap = 'gray') # The display is done by truncating the dynamic\n",
        "I_SAR = I_SAR[0:300,0:300]\n",
        "plt.figure()\n",
        "plt.imshow(I_SAR,vmax = 100, cmap = 'gray') # The display is done by truncating the dynamic\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(I_SAR[100:200,100:200].flatten(),200) # Display of the histogram on an almost homogeneous area\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}