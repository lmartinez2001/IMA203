{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3mgm5pieFOY"
      },
      "source": [
        "## PW on graphcut optimization (binary case)\n",
        "This session is divided into 3 parts: \n",
        "\n",
        "\n",
        "* a part on Bayesian classification (see PW1 and PW2)\n",
        "* a part on object/background segmentation of a colour image with a CRF (conditional random filed)\n",
        "* a part on the iterative segmentation of a textured image\n",
        "\n",
        "We will use the PyMaxflow library for the calculation of the graphcut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-fqZE_aeALW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import platform\n",
        "import tempfile\n",
        "import os\n",
        "from scipy import ndimage as ndi\n",
        "try:\n",
        "    import maxflow # if not installed, install Maxflow\n",
        "except:\n",
        "    !pip install PyMaxflow # For Google Collab\n",
        "    import maxflow\n",
        "\n",
        "from skimage import io\n",
        "from bokeh.plotting import figure, output_file, show\n",
        "from bokeh.plotting import show as showbokeh\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "def affiche_pour_colab(im,MINI=None, MAXI=None,titre=''): #special colab, don't look\n",
        "  def normalise_image_pour_bokeh(X,MINI,MAXI):\n",
        "    if MAXI==None:\n",
        "      MAXI = np.max(X)\n",
        "    if MINI==None:\n",
        "      MINI = np.min(X)\n",
        "    imt=np.copy(X.copy())\n",
        "    imt=(np.clip(imt,MINI,MAXI)/(MAXI-MINI))\n",
        "    imt[imt<0]=0\n",
        "    imt[imt>1]=1\n",
        "    imt*=255\n",
        "    sortie=np.empty((*imt.shape,4),dtype=np.uint8)\n",
        "    for k in range(3):\n",
        "      sortie[:,:,k]=imt\n",
        "    sortie[:,:,3]=255\n",
        "    return sortie\n",
        "\n",
        "  img = im\n",
        "  img=normalise_image_pour_bokeh(np.flipud(im),MINI,MAXI)\n",
        "  p = figure(tooltips=[(\"x\", \"$x\"), (\"y\", \"$y\"), (\"value\", \"@image\")], y_range=[im.shape[0], 0], x_range=[0, im.shape[1]], title=titre)\n",
        "  # p.x_range.range_padding = p.y_range.range_padding = 0\n",
        "  # must give a vector of images\n",
        "  p.image(image=[np.flipud(im)], x=0, y=im.shape[0], dw=im.shape[1], dh=im.shape[0], palette=\"Greys9\", level=\"image\")\n",
        "  p.xgrid.visible = False\n",
        "  p.ygrid.visible = False\n",
        "  showbokeh(p)\n",
        "\n",
        "def affiche(im,MINI=0.0, MAXI=None,titre='',printname=False):\n",
        "  affiche_pour_colab(im,MINI=MINI, MAXI=MAXI,titre=titre) # under google colab many options disappear\n",
        "\n",
        "def display_segmentation_borders(image, bin):\n",
        "    imagergb = np.copy(image)\n",
        "    from skimage.morphology import binary_dilation, disk\n",
        "    contour = binary_dilation(bin,disk(15))^bin\n",
        "    imagergb[contour==1,0] = 255\n",
        "    imagergb[contour==1,1] = 0\n",
        "    imagergb[contour==1,2] = 0\n",
        "    return imagergb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nndFrzQkeALh"
      },
      "source": [
        "## Binary classification of a noisy image\n",
        "\n",
        "You have a binary image *IoriginaleBW.png* (binary image of the two classes) and its observed version with a certain distribution of grey levels for each class *Iobservee.png*. The objective is to perform a two-class classification of this observed image (see PW1 and PW2). \n",
        "\n",
        "### Analysis of the distributions of the 2 classes of the image}\n",
        "\n",
        "\n",
        "Q1: What are the distributions of the two classes of the image ($P(Y_s|X_s=0)$ (black class) and $P(Y_s|X_s=0)$ (white class))? \n",
        "\n",
        "Q2: Give the means and variances of the two classes.\n",
        "\n",
        "*The distributions and the means and variances found in the previous sessions will be used without justification*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6Re5qCeALh"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A1: \n",
        "\n",
        "A2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjYI0DBieALj"
      },
      "source": [
        "## 1.1: Graphcut optimization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JNLl31geALk"
      },
      "source": [
        "Q3: How many nodes does the graph have that is constructed for the search for the minimum capacity cut with only two neighbouring pixels? What do they correspond to? What do the data attachment terms in this graph correspond to and what values do they have for two observed pixels of values $y_s$ and $y_t$? What does the regularisation term correspond to?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ7V-ZL8eALl"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_eBP8w7eALl"
      },
      "source": [
        "Q4: Complete the python code cell where it says \"#TO BE COMPLETED EX1\" with the data attachment and regularization terms as indicated. Run the minimum cut algorithm and view the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcNyoI-3kP_4"
      },
      "source": [
        "## 1.2 Searching for the optimal $\\beta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFgB73kLeALn"
      },
      "source": [
        "\n",
        "\n",
        "Q5: By completing the program frame provided below, find the optimal $\\beta$ value $\\beta_{opt}$ using the \"true image\" $x$ corresponding to IoriginaleBW.png. You can plot the error values between $x$ and the estimated $\\hat{x}$ to find $\\beta_{opt}$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEv5jM1KeALo"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A5:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9VAuDBJgrLx"
      },
      "source": [
        "Q6: What are the advantages of this optimization approach compared to ICM? Compared to simulated annealing? In theory, do we obtain the same result with both methods (simulated annealing and graphcut)? Under what conditions? What is the advantage of simulated annealing in the general case?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uqBSHTkgw6P"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A6: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9SgH432eALp"
      },
      "source": [
        "\n",
        "Q7: How can you explain that the error rate with the true image can be lower with the simulated annealing result or the ICM than with the graph-cut optimisation? \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzFxm1useALq"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A7:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjgmIJCjjUPV"
      },
      "source": [
        "Q8: What are the advantages and disadvantages of the Ising model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQNFzj8Jjett"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRdTaqnheALq"
      },
      "outputs": [],
      "source": [
        "# Loading images\n",
        "im_obs=io.imread(\"https://perso.telecom-paristech.fr/tupin/cours/IMA203/TPMARKOV/Iobservee.png\") # Observed image, noisy\n",
        "im_orig=io.imread(\"https://perso.telecom-paristech.fr/tupin/cours/IMA203/TPMARKOV/IoriginaleBW.png\") # Binary reference image, to assess the quality of the segmentation\n",
        "\n",
        "affiche(im_obs,titre='Observed image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0YUOGyqeALq"
      },
      "outputs": [],
      "source": [
        "#### to be completed\n",
        "# TO BE COMPLETED EX1\n",
        "beta =  # beta value \n",
        "m0 =    # m0 and m1 values from the previous practical work\n",
        "m1 = \n",
        "\n",
        "## binary graph-cut\n",
        "\n",
        "# Create the graph.\n",
        "g = maxflow.Graph[float]() # Graph instantiation\n",
        "\n",
        "# Add the nodes. \n",
        "# nodeids has the identifiers of the nodes in the grid.\n",
        "# It creates a set of nodes for all the pixels of the image\n",
        "nodeids = g.add_grid_nodes(im_obs.shape) \n",
        "\n",
        "# Add non-terminal edges with the same capacity.\n",
        "# the edge has the value beta for all adjacent pixels in 4-connexity\n",
        "g.add_grid_edges(nodeids, beta) \n",
        "\n",
        "# Add the terminal edges.\n",
        "# the second argument correspond to the set of edge values to the source \n",
        "# the third argument correspond to the set of edge values to the sink\n",
        "g.add_grid_tedges(nodeids, (im_obs-m0)**2, (im_obs-m1)**2) \n",
        "\n",
        "# Find the maximum flow.\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "# Get the labels of the nodes in the grid.\n",
        "# output is 0 if the node is connected to the source, else output is 1 \n",
        "sgm = g.get_grid_segments(nodeids) \n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "affiche(im_bin,titre = \"Result for beta = \" + str(beta))\n",
        "#%%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWDVl5ceeALr"
      },
      "outputs": [],
      "source": [
        "# compute the error image between im_bin and im_orig (the ideal solution) using np.abs and np.sum \n",
        "error = \n",
        "\n",
        "# visualize the differences between the original image and the solution\n",
        "plt.figure()\n",
        "plt.imshow(np.dstack((np.int_(im_orig), im_bin, im_bin))*255)\n",
        "plt.title(\"Result for beta = \" + str(beta) + \" and truth\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Number of misclassified pixels for beta = \",beta,\": \",int(error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD0sTgGoeALr"
      },
      "source": [
        "### Search for the best parameter $\\beta$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf5x86KgeALs"
      },
      "outputs": [],
      "source": [
        "im_obs=io.imread(\"https://perso.telecom-paristech.fr/tupin/cours/IMA203/TPMARKOV/Iobservee.png\") # Observed image, noisy\n",
        "im_orig=io.imread(\"https://perso.telecom-paristech.fr/tupin/cours/IMA203/TPMARKOV/IoriginaleBW.png\") # Binary reference image, to assess the quality of the segmentation\n",
        "\n",
        "list_beta = []\n",
        "list_errors = []\n",
        "\n",
        "# TO BE COMPLETED - choose a range of values and a step to study beta\n",
        "for beta in range():\n",
        "    # TO BE COMPLETED\n",
        "    m0 = \n",
        "    m1 =\n",
        "\n",
        "    ## Binary graph cut\n",
        "\n",
        "    # Create the graph\n",
        "    g = maxflow.Graph[float]() # graph instantiation\n",
        "\n",
        "    # Add the nodes. nodeids has the identifiers of the nodes in the grid.\n",
        "    nodeids = g.add_grid_nodes(im_obs.shape) \n",
        "    # Add non-terminal edges with the same capacity.\n",
        "    g.add_grid_edges() \n",
        "    # Add the terminal edges.\n",
        "    g.add_grid_tedges(nodeids, ,) \n",
        "\n",
        "    # Find the maximum flow.\n",
        "    flow = g.maxflow()\n",
        "\n",
        "    # Get the segments of the nodes in the grid.\n",
        "    sgm = g.get_grid_segments() \n",
        "    # create the output image \n",
        "    im_bin = np.int_()\n",
        "\n",
        "    # print(\"beta = \",beta)\n",
        "    # compute the error\n",
        "    error = \n",
        "    list_beta.append(beta)\n",
        "    list_errors.append(error)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(list_beta,list_errors)\n",
        "plt.xlabel(\"beta\")\n",
        "plt.ylabel(\"number of misclassified pixels\")\n",
        "plt.show()\n",
        "\n",
        "best_beta = list_beta[np.argmin(np.array(list_errors))]\n",
        "\n",
        "print('Best beta value: ', best_beta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDJDhepieALs"
      },
      "source": [
        "## 2. Classification of a colour image\n",
        "\n",
        "The objective of this part is to carry out an extension of the method seen previously in the case of the treatment of a colour image *avions.png* in which one wants to separate the objects from the background.\n",
        "\n",
        "We will first use the same framework (Ising model) as before but with a three-dimensional data attachment (assuming convariance matrices equal to the identity). Then we will introduce a CRF (conditional random field) by weighting the regularisation term of the Ising model by the modulus of the gradient between two pixels of the observed image.  \n",
        "\n",
        "### 2.1 Binary classification\n",
        "From the program structure below, carry out the different steps necessary for this classification:\n",
        "1. Modelling of the background and object distributions (in 3 dimensions this time)\n",
        "1. Definition of the data attachment term\n",
        "1. Choice of a value for the regularisation parameter for the Ising model\n",
        "1. Finding the minimal cut to obtain the object/background classification.\n",
        "\n",
        "Q9: Comment on these steps and the results obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfXuLLE4eALs"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A9:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk1Nj14meALs"
      },
      "outputs": [],
      "source": [
        "# Loading and displaying the image\n",
        "im_obs=io.imread('https://www.dropbox.com/s/ylm0ut8ipu5oonb/avions.png?dl=1')\n",
        "\n",
        "plt.figure()\n",
        "#plt.imshow(im_obs,vmin=0,vmax=255)\n",
        "plt.rcParams['figure.figsize'] = [15, 15]\n",
        "plt.imshow(im_obs)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# conversion of the image between 0 and 255\n",
        "im_obs=255*im_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPsAftnceALt"
      },
      "source": [
        "#### Determining the parameters of the classes\n",
        "\n",
        "\n",
        "Plane class: we can use the values of the rectangle [180:200,280:300]. \n",
        "\n",
        "example np.mean(image[180:200,280:300,1]) returns the average of the selected area for channel 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16tOLr7ZeALt"
      },
      "outputs": [],
      "source": [
        "# mean of the plane class - 3D vector\n",
        "m_planes = \n",
        "\n",
        "# mean of the sky class\n",
        "# you can use values in the following square [0:100,150:300]\n",
        "m_sky = \n",
        "\n",
        "print('For the sky, [R,G,B] = ', m_sky)\n",
        "print(\"For the planes, [R,G,B] = \", m_planes)\n",
        "\n",
        "# check that the obtained values are coherent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF7ZH7EveALu"
      },
      "outputs": [],
      "source": [
        "# choose a beta value \n",
        "beta = \n",
        "\n",
        "# TO BE COMPLETED\n",
        "## Binary graph-cut \n",
        "# use the previous program to create the graph and compute the cut\n",
        "# be careful of computing the terminal weights using the 3D values \n",
        "# you can compute 2 distance images with in each pixel the quadratic distance to the mean value \n",
        "# of each class \n",
        "\n",
        "\n",
        "\n",
        "affiche(im_bin, titre=\"Result for beta = \" + str(beta));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwxEgcMyeALu"
      },
      "source": [
        "### 2.2 Use of a CRF (Conditional Random Field) model\n",
        "\n",
        "We will try here to adapt the model used previously to favour transitions where they are compatible with the gradient. To do this, we will replace the constant $\\beta$ for the whole image by a \"beta_field\" which depends on the norm of the gradient.\n",
        "\n",
        "Q10: Calculate and display the modulus of the gradient of the aircraft image after it has been grayscaled and convolved by a Gaussian kernel of standard deviation 1. Why use the \"boundary='symm'\" option when convolving through the Sobel filter? Try it without doing the Gaussian filtering. What is the point?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT3EdCcMuH5E"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROpDhuB-eALv"
      },
      "outputs": [],
      "source": [
        "import scipy.signal\n",
        "import scipy.ndimage\n",
        "from skimage import color\n",
        "\n",
        "def gradient(image):\n",
        "    \"\"\" Array -> tuple[Array*Array]\"\"\"\n",
        "    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype = np.float)\n",
        "    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype = np.float)\n",
        "    # to be completed\n",
        "    # use mode = 'same' and boundary='symm' in scipy.signal.convolve2d\n",
        "    derivative_x = \n",
        "    derivative_y = \n",
        "    return([derivative_x,derivative_y])\n",
        "\n",
        "plane_nb = scipy.ndimage.gaussian_filter(color.rgb2gray(im_obs), 1)\n",
        "plane_x, plane_y = gradient(plane_nb)\n",
        "# calculation of the gradient modulus \n",
        "grad_av = \n",
        "plt.figure()\n",
        "plt.imshow(grad_av)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnT3Y0zOt_lN"
      },
      "source": [
        "\n",
        "Complete the code for segmentation by CRF. We will choose $beta\\_field=\\beta_2\\cdot\\exp(-grad\\_av/h)$ We can use $h=300$ and $\\beta_2=20000$. Also replace the constant beta by the field \"beta_field\" during the \"g.add_grid_edges\" step.\n",
        "\n",
        "Q11: Compare the results with and without the contour term."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm01udUIxIHt"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A11:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imKywIsReALw"
      },
      "outputs": [],
      "source": [
        "# calculation of beta_field \n",
        "# this field will set the value for the 4-neighbours \n",
        "h = 300\n",
        "beta2 = 20000\n",
        "beta_field = beta2 * np.exp(-grad_av/h)\n",
        "\n",
        "## Binary graph cut\n",
        "# complete by taking your previous code and replacing \n",
        "# beta by beta_field in the line g.add_grid_edges\n",
        "\n",
        "\n",
        "# Get the segments of the nodes in the grid.\n",
        "sgm = g.get_grid_segments(nodeids) # Returns 1 if the pixel is on the drain side after calculating the min cut, 0 if it is on the source side\n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "affiche(im_bin, titre=\"Result for the CRF model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ezFoD6eALw"
      },
      "source": [
        "## 3. Iterative Segmentation with Gaussian Mixture\n",
        "\n",
        "Q12: Display the \"zebra\" image below. Is it possible to segment the zebra with the method used to segment the planes?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9E-e1IyydI-"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A12:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS9FTw3aeALw",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "### Loading a new image\n",
        "import imageio\n",
        "I_zebra = imageio.imread('https://upload.wikimedia.org/wikipedia/commons/6/60/Equus_quagga.jpg')\n",
        "I_zebra = I_zebra[200:,:,:]\n",
        "rect_zebra = I_zebra[700:1100,1000:2100]\n",
        "rect_background = I_zebra[:,0:600]\n",
        "print(I_zebra.dtype)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(I_zebra)\n",
        "plt.title('I_zebra')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(rect_zebra)\n",
        "plt.title('rect_zebra')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(rect_background)\n",
        "plt.title('rect_background')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HGzR7tSeALx"
      },
      "source": [
        "Q13: Calculate the covariance matrix for the rect_zebra and the rect_background. Display the values and comment on the result. What do the diagonal values correspond to?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A13:"
      ],
      "metadata": {
        "id": "BtKlw5ehRHzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRsXhxJGeALx"
      },
      "outputs": [],
      "source": [
        "print(I_zebra.shape)\n",
        "V_tulip = np.vstack([I_zebra[:,:,i].flatten() for i in range(3)])\n",
        "print(I_zebra.shape)\n",
        "\n",
        "M_cov = np.cov(np.vstack([I_zebra[:,:,i].flatten() for i in range(3)]))\n",
        "print('Full zebra image')\n",
        "print(M_cov)\n",
        "\n",
        "M_cov = np.cov(np.vstack([rect_zebra[:,:,i].flatten() for i in range(3)]))\n",
        "print('Rectangle zebra')\n",
        "print(M_cov)\n",
        "\n",
        "M_cov = np.cov(np.vstack([rect_background[:,:,i].flatten() for i in range(3)]))\n",
        "print('Rectangle background')\n",
        "print(M_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8YAfUvJeALx"
      },
      "source": [
        "Q14: Display the histogram for the R, G and B channels for the \"rect_zebra\" image. Comment on the result. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A14:"
      ],
      "metadata": {
        "id": "1_p_ddriRMTq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuZg14rbeALx"
      },
      "outputs": [],
      "source": [
        "# allows you to change the display size of plt.show\n",
        "plt.rcParams['figure.figsize'] = [11, 11]\n",
        "\n",
        "nomchan = [\"red\",\"green\", \"blue\"]\n",
        "for chan in range(3):\n",
        "    plt.figure()\n",
        "    plt.hist(rect_zebra[:,:,chan].flatten(),100)\n",
        "    plt.title(\"Histogram of the zebra class for the channel \" + nomchan[chan])\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "for chan in range(3):\n",
        "    plt.figure()\n",
        "    plt.hist(rect_background[:,:,chan].flatten(),100)\n",
        "    plt.title(\"Histogram of the background class for the channel \" + nomchan[chan])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDjO5aL5eALy"
      },
      "source": [
        "Q15: Propose an algorithmic method to identify the two classes of the image \"rect_zebra\". Use a sklearn implementation of this algorithm to identify the mean vectors ($m_R$,$m_G$,$m_B$) for two classes of the \"rect_zebra\" image and two classes of the \"rect_background\" image.\n",
        "\n",
        "*The following line of code can be used to transform the image into a suitable form.*\n",
        "\n",
        "X = np.vstack([rect_zebra[:,:,i].flatten() for i in range(3)]).transpose()\n",
        "\n",
        "Comment on the average vectors obtained. They can be displayed as an image using the code provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5XoOjc1531V"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A15:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyOzSp13eALy"
      },
      "outputs": [],
      "source": [
        "# computation of class parameters in a semi-automatic way\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# use a number of classes =2 for the zebra part (complete n_clusters=?)\n",
        "X = np.vstack([rect_zebra[:,:,i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_zebra = KMeans(n_clusters=, random_state=0).fit(X)\n",
        "mean_vectors_zebra = kmeans_zebra.cluster_centers_\n",
        "\n",
        "# use a number of classes =2 for the background part\n",
        "X = np.vstack([rect_background[:,:,i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_background = KMeans(n_clusters=, random_state=0).fit(X)\n",
        "mean_vectors_background = kmeans_background.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yxiv4ZmUeALz"
      },
      "outputs": [],
      "source": [
        "# display of the class centers found as an image\n",
        "image_mean_vectors = np.zeros((200,200,3),np.uint8)\n",
        "for i in range(3):\n",
        "    image_mean_vectors[0:99,0:99,i] = mean_vectors_zebra[0,i]\n",
        "    image_mean_vectors[0:99,100:199,i] = mean_vectors_zebra[1,i]\n",
        "    image_mean_vectors[100:199,0:99,i] = mean_vectors_background[0,i]\n",
        "    image_mean_vectors[100:199,100:199,i] = mean_vectors_background[1,i]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image_mean_vectors,vmax = 255)\n",
        "plt.title(\"Top: zebra classes, bottom: background classes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m7NevXDeALz"
      },
      "source": [
        "Q16: Display separately two neg-log-likelihood images (the neg-log-likelihood was used as a data attachment in the previous example) for the two zebra classes.\n",
        "Build a neg-log-likelihood image corresponding to the minimum of the two neg-log-likelihoods of the zebra classes. Similarly for the background class. \n",
        "\n",
        "Display them and comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMXjRkeH0xVp"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A16:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhZk35freALz"
      },
      "outputs": [],
      "source": [
        "# calculation of the neg-log-likelihood of the zebra class\n",
        "neg_log_likelihood_zebra_0 = sum((I_zebra[:,:,i]-mean_vectors_zebra[0,i])**2 for i in range(3))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_0,cmap='gray', vmax = 600)\n",
        "plt.title(\"neg_log_likelihood_zebra_0\")\n",
        "plt.show()\n",
        "\n",
        "neg_log_likelihood_zebra_1 = sum((I_zebra[:,:,i]-mean_vectors_zebra[1,i])**2 for i in range(3))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_1,cmap='gray', vmax = 5000)\n",
        "plt.title(\"neg_log_likelihood_zebra_1\")\n",
        "plt.show()\n",
        "\n",
        "neg_log_likelihood_zebra_combined = np.minimum(sum((I_zebra[:,:,i]-mean_vectors_zebra[0,i])**2 for i in range(3)),sum((I_zebra[:,:,i]-mean_vectors_zebra[1,i])**2 for i in range(3)))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_combined,cmap='gray', vmax = 5000)\n",
        "plt.title(\"neg_log_likelihood_zebra_combined\")\n",
        "plt.show()\n",
        "\n",
        "# TO BE COMPLETED\n",
        "# calculate the neg-log-likelihood of the background \n",
        "# call the output neg_log_likelihood_background_combined\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDrVWWxQeALz"
      },
      "source": [
        "Q17: From these combined data attachment images (one for the background and one for the zebra), set up a graph-cut segmentation of the image with the $\\beta$ of your choice. Comment the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81C1KbDr2XoW"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A17:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECAh3_eCeALz"
      },
      "outputs": [],
      "source": [
        "beta =  # Optimal beta value to be determined\n",
        "\n",
        "## Binary graph cut\n",
        "\n",
        "# Create the graph.\n",
        "g = maxflow.Graph[float]() # Graph instantiation\n",
        "# Add the nodes. nodeids has the identifiers of the nodes in the grid.\n",
        "nodeids = g.add_grid_nodes(I_zebra.shape[0:2]) # Create a grid with a non-terminal node for each pixel in the image\n",
        "# Add non-terminal edges with the same capacity.\n",
        "g.add_grid_edges(nodeids, beta) # Addition of a beta weight edge between each adjacent node according to the 4-connexity\n",
        "# Add the terminal edges.\n",
        "\n",
        "# TO BE COMPLETED\n",
        "g.add_grid_tedges() \n",
        "\n",
        "\n",
        "# Find the maximum flow.\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "# Get the segments of the nodes in the grid.\n",
        "sgm = g.get_grid_segments(nodeids) \n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im_bin)\n",
        "plt.title(\"Result of the segmentation\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(display_segmentation_borders(I_zebra, im_bin))\n",
        "plt.title(\"Red segmentation contours\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9x_xqQheAL0"
      },
      "source": [
        "Q18: From the obtained segmentation, determine the mean vectors for 5 classes for the background and 5 classes for the zebra. Use these lists of mean vectors to construct new neg-log-likelihood combination images. Comment on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldB8fTnL3fqw"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A18:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vwje0HN6eAL0"
      },
      "outputs": [],
      "source": [
        "# The computing of this cell can take several minutes.\n",
        "\n",
        "X_1 = np.vstack([I_zebra[im_bin==1,i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_zebra2 = KMeans(n_clusters=5, random_state=0).fit(X_1)\n",
        "mean_vectors_zebra2 = kmeans_zebra2.cluster_centers_\n",
        "\n",
        "X_2 = np.vstack([I_zebra[im_bin==0,i].flatten() for i in range(3)]).transpose()\n",
        "kmeans_background2 = KMeans(n_clusters=5, random_state=0).fit(X_2)\n",
        "mean_vectors_background2 = kmeans_background2.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C90SebBkeAL1"
      },
      "outputs": [],
      "source": [
        "neg_log_likelihood_zebra_combined_2 = np.amin(np.dstack([(sum((I_zebra[:,:,i]-mean_vectors_zebra2[n_cl,i])**2 for i in range(3))) for n_cl in range(len(mean_vectors_zebra2))]),2)\n",
        "\n",
        "neg_log_likelihood_background_combined_2 = np.amin(np.dstack([(sum((I_zebra[:,:,i]-mean_vectors_background2[n_cl,i])**2 for i in range(3))) for n_cl in range(len(mean_vectors_background2))]),2)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_zebra_combined_2 ,cmap='gray', vmax = 3000)\n",
        "plt.title(\"neg_log_likelihood_zebra_combined_2\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(neg_log_likelihood_background_combined_2,cmap='gray', vmax = 1000)\n",
        "plt.title(\"neg_log_likelihood_background_combined_2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyREjjNVeAL2"
      },
      "source": [
        "\n",
        "Q19: From these neg-log-likelihood images, segment the image by graph-cut using a new value of $\\beta$ that gives you the best result. Comment on the result and the new value of $\\beta$ that allowed you to obtain it. What about the new 5-class data attachment compared to the previous one?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5DbiDd75afC"
      },
      "source": [
        "**Your answer &#x270D;**\n",
        "\n",
        "A19:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx8dBjfjeAL2"
      },
      "outputs": [],
      "source": [
        "beta =  # Optimal beta value to be determined\n",
        "\n",
        "g = maxflow.Graph[float]() # Graph instantiation\n",
        "# Add the nodes. nodeids has the identifiers of the nodes in the grid.\n",
        "nodeids = g.add_grid_nodes(I_zebra.shape[0:2]) \n",
        "# Add non-terminal edges with the same capacity.\n",
        "g.add_grid_edges(nodeids, beta)\n",
        "# Add the terminal edges.\n",
        "g.add_grid_tedges(nodeids,neg_log_likelihood_background_combined_2, neg_log_likelihood_zebra_combined_2) \n",
        "\n",
        "flow = g.maxflow()\n",
        "\n",
        "print(\"Max Flow:\", str(flow))\n",
        "# Get the segments of the nodes in the grid.\n",
        "sgm = g.get_grid_segments(nodeids) # Returns 1 if the pixel is on the drain side after calculation of the min cut, 0 if it is on the source side\n",
        "im_bin = np.int_(np.logical_not(sgm))\n",
        "\n",
        "affiche(im_bin, titre=\"Result for beta = \" + str(beta))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im_bin)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(display_segmentation_borders(I_zebra, im_bin))\n",
        "plt.title(\"Red segmentation contours\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}